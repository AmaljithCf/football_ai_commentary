{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_commentary_gpt2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj0p_tUOy6hx",
        "colab_type": "text"
      },
      "source": [
        "# AI generated sports commentary \\[[blog](https://medium.com/@chintan.t93)\\] \\[[video](https://www.youtube.com/watch?v=p9AmkiG8UeI)\\] \\[[code](https://github.com/ChintanTrivedi/football_ai_commentary)\\]\n",
        "\n",
        "This notebook is for training a GPT-2 language model to perform on-the-fly commentary for football/soccer games.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX8BYebL2A4_",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "Clone the GPT-2 repo, install dependencies and download the pre-trained model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK-kzkdMpDyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/nshepperd/gpt-2.git\n",
        "%cd gpt-2\n",
        "!pip3 install -r requirements.txt\n",
        "!python3 download_model.py 345M\n",
        "!pip install webvtt-py youtube_dl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngNvRdjr3uFe",
        "colab_type": "text"
      },
      "source": [
        "## Train GPT-2\n",
        "\n",
        "### Training Data \n",
        "- Using YouTube videos of full matches of FIFA and PES video games providing commentary in its audio\n",
        "- Currently using manual or automated captions obtained directly from YouTube API.\n",
        "- Captions are downloaded in .webvtt format, which are converted to plain text transcript\n",
        "- Unfortunately, this does not provide any punctuations in the text, so need to look into alternate text-to-speech options (ones I tried currently do not work)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDuIWwqNhQFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_training_data = True # required only if you're looking to retrain\n",
        "\n",
        "if download_training_data:\n",
        "  # YouTube URLs of full FIFa/PES matches with uninterrupted game commentary\n",
        "  urls = [\n",
        "      'https://www.youtube.com/watch?v=_QL2Vr-Rbhk',    'https://www.youtube.com/watch?v=vW2pn2LsrZU',    'https://www.youtube.com/watch?v=795ttHjcuNA',\n",
        "      'https://www.youtube.com/watch?v=g8IVEuGy3dk',    'https://www.youtube.com/watch?v=4Kq4hoCWG4c',    'https://www.youtube.com/watch?v=43FbmrkHoiY',\n",
        "      'https://www.youtube.com/watch?v=O6lVXP1XJrc',    'https://www.youtube.com/watch?v=51Lal4CqJfM',    'https://www.youtube.com/watch?v=-9JXEzCUmKE',\n",
        "      'https://www.youtube.com/watch?v=r7bsamy9n5c',    'https://www.youtube.com/watch?v=tFf5HiuK6v0',    'https://www.youtube.com/watch?v=Na44QV_Q7ic',\n",
        "      'https://www.youtube.com/watch?v=iKkkRqBL3pM',    'https://www.youtube.com/watch?v=NWBKXU5boRg',    'https://www.youtube.com/watch?v=A68hJll7Us4',\n",
        "      'https://www.youtube.com/watch?v=Ch-1BQmTzWI',    'https://www.youtube.com/watch?v=67roKfGj_Fo',    'https://www.youtube.com/watch?v=Euei-fpFlrQ',\n",
        "      'https://www.youtube.com/watch?v=2JS_6foNnP8',    'https://www.youtube.com/watch?v=pDsabB1HVAM',    'https://www.youtube.com/watch?v=6_h6FpHnuIs',\n",
        "      'https://www.youtube.com/watch?v=PkSv__cAYfw',    'https://www.youtube.com/watch?v=gRUWMIL9l8g',    'https://www.youtube.com/watch?v=s-iqqWnmgkc',\n",
        "      'https://www.youtube.com/watch?v=mOFAP0KF2x4',    'https://www.youtube.com/watch?v=E1I9eof_szE',    'https://www.youtube.com/watch?v=fZxanp6sP8c',\n",
        "      'https://www.youtube.com/watch?v=l3VQ1jC2Iyg',    'https://www.youtube.com/watch?v=l3VQ1jC2Iyg',    'https://www.youtube.com/watch?v=l3VQ1jC2Iyg',\n",
        "      'https://www.youtube.com/watch?v=qrKbmzYGLEM',    'https://www.youtube.com/watch?v=B8ImIuKQSHg',    'https://www.youtube.com/watch?v=xGh4GciXPQk',\n",
        "      'https://www.youtube.com/watch?v=1ISKxiGw4K8',    'https://www.youtube.com/watch?v=ShkyV3DyTD4',    'https://www.youtube.com/watch?v=XYlDNfS48sg',\n",
        "      'https://www.youtube.com/watch?v=_jT2uZLxA7o',    'https://www.youtube.com/watch?v=TNMG98EhKLU',    'https://www.youtube.com/watch?v=TRX-BmKdltY',\n",
        "      'https://www.youtube.com/watch?v=nAEvAxInIV0',    'https://www.youtube.com/watch?v=RWaOoa0UMcI',    'https://www.youtube.com/watch?v=XJRLRxDC3x0',\n",
        "      'https://www.youtube.com/watch?v=Ye4cVwfSdAc',    'https://www.youtube.com/watch?v=cF3junSjIAA',    'https://www.youtube.com/watch?v=d18-39m9NoE',\n",
        "      'https://www.youtube.com/watch?v=rzOddgKPPtI',    'https://www.youtube.com/watch?v=px4EAg0Vbg4',    'https://www.youtube.com/watch?v=-DQuJTTcbdw',\n",
        "      'https://www.youtube.com/watch?v=3_B3smljvkQ',    'https://www.youtube.com/watch?v=3us3vUoLkac',    'https://www.youtube.com/watch?v=ol4WW_IVGOQ',\n",
        "      'https://www.youtube.com/watch?v=2cLT4mTqWz4',    'https://www.youtube.com/watch?v=TPZPB2uCh8k',    'https://www.youtube.com/watch?v=JuDngE09WhE',\n",
        "      'https://www.youtube.com/watch?v=9rRp2gDE7Yc',    'https://www.youtube.com/watch?v=hqrlgNP7E-0',    'https://www.youtube.com/watch?v=fXhf9Yh7tf8',\n",
        "      'https://www.youtube.com/watch?v=jV3FUzCqQAQ',    'https://www.youtube.com/watch?v=uhBw9DO-z7A',    'https://www.youtube.com/watch?v=rczhz6xeIfQ'\n",
        "  ]\n",
        "\n",
        "  import webvtt\n",
        "  import requests\n",
        "  import os\n",
        "  import youtube_dl\n",
        "  import re\n",
        "\n",
        "  if not os.path.exists('captions'):\n",
        "      os.makedirs('captions')\n",
        "\n",
        "  # final training data file for all videos combined    \n",
        "  f_train = open(\"commentary_train.txt\", \"w\")\n",
        "\n",
        "  # download captions only for all urls\n",
        "  for ix, url in enumerate(urls):\n",
        "    ydl = youtube_dl.YoutubeDL({'writesubtitles': True, 'allsubtitles': True, 'writeautomaticsub': True})\n",
        "    res = ydl.extract_info(url, download=False)\n",
        "    if res['requested_subtitles'] and res['requested_subtitles']['en']:\n",
        "      print('Grabbing vtt file from ' + res['requested_subtitles']['en']['url'])\n",
        "      response = requests.get(res['requested_subtitles']['en']['url'], stream=True)\n",
        "\n",
        "      f1 = open(\"captions/commentary{}.txt\".format(ix), \"w\")\n",
        "      f1.write(response.text)\n",
        "      f1.close()\n",
        "      if len(res['subtitles']) > 0:\n",
        "        print('manual captions')\n",
        "      else:\n",
        "        print('automatic_captions')\n",
        "    else:\n",
        "      print('Youtube Video does not have any english captions')\n",
        "      continue\n",
        "\n",
        "    # convert downloaded webvtt file to plain text transcript\n",
        "    vtt = webvtt.read(\"captions/commentary{}.txt\".format(ix))\n",
        "    transcript = \"\"\n",
        "\n",
        "    lines = []\n",
        "    for line in vtt:\n",
        "        lines.extend(line.text.strip().splitlines())\n",
        "\n",
        "    previous = None\n",
        "    for line in lines:\n",
        "        if line == previous:\n",
        "           continue\n",
        "        transcript += \" \" + line\n",
        "        previous = line\n",
        "\n",
        "    print(transcript)\n",
        "    # replace [Music] and [Applause] keywords that appear in youtube captions before writing transcript\n",
        "    f_train.write(re.sub('\\[.*?\\]','',transcript)+'\\n')\n",
        "\n",
        "  f_train.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PydIq05L9rct",
        "colab_type": "text"
      },
      "source": [
        "## Model Training\n",
        "- Uncomment the following and run to train again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4nTK-zT9r2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset /content/gpt-2/commentary_train.txt --model_name '345M'\n",
        "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/345M/\n",
        "# !cp -r /content/gpt-2/checkpoint/ /content/drive/My\\ Drive/\n",
        "# !cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/345M/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w4tRxnuiE4K",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOLAyMnBk32",
        "colab_type": "text"
      },
      "source": [
        "- Here, I'm just going to pull the model I've trained before from my Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhKq2gwlDFvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!zip run1.zip ./checkpoint/run1/*\n",
        "!cp run_2.zip /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYWnuekZHhef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r /content/drive/My\\ Drive/checkpoint/run1/* /content/gpt-2/models/345M/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJKCVIILFFR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd models/345M/\n",
        "!rm checkpoint\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1iTRezA2oe2B58wDx3FcZosqdcyD06Kwt' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1iTRezA2oe2B58wDx3FcZosqdcyD06Kwt\" -O run1.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip run1.zip\n",
        "%cd ../.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORykR3UrCCFr",
        "colab_type": "text"
      },
      "source": [
        "## Play with the model's conditional samples using a prompt\n",
        "Example of prompts: \n",
        "- That was a really poor pass. You expect a player of his quality to do better.\n",
        "- What a goal! Wonderful strike from the team captain.\n",
        "- Welcome to today's game between two top teams in Europe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXcnxfPHJFVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 40 --model_name \"345M\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcTx_w66BxAR",
        "colab_type": "text"
      },
      "source": [
        "# EXPERIMENTAL CODE\n",
        "\n",
        "## Freeze model checkpoint to pb file for real-time inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0JRKLAaKf6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import fire\n",
        "# import json\n",
        "# import os\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "\n",
        "# import model, sample, encoder\n",
        "\n",
        "# seed=None\n",
        "# length=40\n",
        "# temperature=1\n",
        "# top_k=0\n",
        "\n",
        "# hparams = model.default_hparams()\n",
        "# with open('models/345M/hparams.json') as f:\n",
        "#   hparams.override_from_dict(json.load(f))\n",
        "\n",
        "# with tf.Session(graph=tf.Graph()) as sess:\n",
        "#   context = tf.placeholder(tf.int32, [1, None])\n",
        "#   np.random.seed(seed)\n",
        "#   tf.set_random_seed(seed)\n",
        "#   output = sample.sample_sequence(\n",
        "#       hparams=hparams, length=length,\n",
        "#       context=context,\n",
        "#       batch_size=1,\n",
        "#       temperature=temperature, top_k=top_k\n",
        "#   )\n",
        "\n",
        "#   saver = tf.train.Saver()\n",
        "#   ckpt = tf.train.latest_checkpoint(os.path.join('models', '345M'))\n",
        "#   saver.restore(sess, ckpt)\n",
        "  \n",
        "#   print([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
        "  \n",
        "#   # Freeze the graph\n",
        "#   frozen_graph_def = tf.graph_util.convert_variables_to_constants(sess,sess.graph_def,[output.name])\n",
        "  \n",
        "#   # Save the frozen graph\n",
        "#   with open('output_graph.pb', 'wb') as f:\n",
        "#     f.write(frozen_graph_def.SerializeToString())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1d9wD1mC0--",
        "colab_type": "text"
      },
      "source": [
        "## Alternate speech to text methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhAXIkA3ZOP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install youtube_dl\n",
        "# import youtube_dl\n",
        "\n",
        "# from __future__ import unicode_literals\n",
        "# import youtube_dl\n",
        "\n",
        "\n",
        "# ydl_opts = {\n",
        "#     'format': 'bestaudio/best',\n",
        "#     'postprocessors': [{\n",
        "#         'key': 'FFmpegExtractAudio',\n",
        "#         'preferredcodec': 'wav',\n",
        "#         'preferredquality': '192',\n",
        "#     }],\n",
        "# }\n",
        "# with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "#     ydl.download(['https://www.youtube.com/watch?v=vW2pn2LsrZU'])\n",
        "\n",
        "# !pip install SpeechRecognition\n",
        "\n",
        "# # import speech_recognition as sr\n",
        "# r = sr.Recognizer()\n",
        "# with sr.AudioFile(\"FIFA 17 _ FC Bayern Munich vs FC Barcelona - Full Gameplay (PS4_Xbox One)-vW2pn2LsrZU.wav\") as source:\n",
        "#     audio = r.record(source)\n",
        "\n",
        "# try:\n",
        "#     s = r.recognize_google(audio)\n",
        "#     print(\"Text: \"+s)\n",
        "# except Exception as e:\n",
        "#     print(\"Exception: \"+str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}